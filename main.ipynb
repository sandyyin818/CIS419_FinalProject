{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
      "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
      "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
      "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
      "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "1             0        0       0       0              0  \n",
      "2             0        0       0       0              0  \n",
      "3             0        0       0       0              0  \n",
      "4             0        0       0       0              0  \n",
      "5             0        0       0       0              0  \n",
      "6             1        1       0       1              0  \n",
      "7             0        0       0       0              0  \n",
      "8             0        0       0       0              0  \n",
      "9             0        0       0       0              0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# #check file paths for data paths \n",
    "# from os import listdir\n",
    "\n",
    "# #list files/directories in current directory\n",
    "# for file in listdir(\"./\"):\n",
    "#     print(file)\n",
    "    \n",
    "train_path = \"./data/train.csv\"\n",
    "test_path = \"./data/test.csv\"\n",
    "test_labels_path = \"./data/test_labels.csv\"\n",
    "\n",
    "#load data with pandas and return dataframes \n",
    "def load_data(train_path, test_path, test_labels_path):\n",
    "    train = pd.read_csv(train_path)\n",
    "    print(train[0:10])\n",
    "    test = pd.read_csv(test_path)\n",
    "    test_labels = pd.read_csv(test_labels_path)\n",
    "    cols_target = ['obscene','insult','toxic','severe_toxic','identity_hate','threat']\n",
    "    return train, test, test_labels, cols_target\n",
    "\n",
    "\n",
    "train, test, test_labels, cols = load_data(train_path, test_path, test_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #summarize data\n",
    "# def summary():\n",
    "#     labels = train.iloc[:,2:]\n",
    "#     zero = np.where(np.sum(labels,axis=1)==0)\n",
    "#     # Find the unlabelled percentage\n",
    "#     unlabelled = train[(train['toxic']!=1) & (train['severe_toxic']!=1) &\\\n",
    "#                                  (train['obscene']!=1) & (train['threat']!=1) &\\\n",
    "#                                  (train['insult']!=1) & (train['identity_hate']!=1)]\n",
    "#     print(\"Train data length: \", len(train))\n",
    "#     print(\"Test data length: \", len(test))\n",
    "#     print('\\nPercentage of unlabelled: ', len(unlabelled)/len(train)*100)\n",
    "#     print(train[cols].sum())\n",
    "\n",
    "#     train[cols].sum().plot.bar(title =\"Number of Comments by Label\")\n",
    "\n",
    "# summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(num_to_use): \n",
    "    #temporarily only use 500 \n",
    "    train_comments = train.iloc[0:num_to_use,1]\n",
    "    test_comments = test.iloc[0:num_to_use,1]\n",
    "    \n",
    "    return test_comments, train_comments\n",
    "\n",
    "test_comments, train_comments= get_data(len(train))\n",
    "\n",
    "\n",
    "# each label as a single combined string, e.g. toxic & severe_toxic = 11\n",
    "def get_labels_as_vec(num_to_use):\n",
    "    #labels as numpy \n",
    "    labels = train.iloc[0:num_to_use,2:]\n",
    "    labels['vector_label'] = labels.astype(str).values.sum(axis=1)\n",
    "    train_labels = labels['vector_label']\n",
    "    return train_labels\n",
    "\n",
    "#alternate : each label as a separate pd column\n",
    "def get_labels_as_cols(num_to_use):\n",
    "    #labels as pd dataframes\n",
    "    toxic_train_labels = train.iloc[0:num_to_use,2:3]\n",
    "    severe_toxic_labels = train.iloc[0:num_to_use,3:4] \n",
    "    obscene_labels = train.iloc[0:num_to_use,4:5] \n",
    "    threat_labels = train.iloc[0:num_to_use,5:6] \n",
    "    insult_labels = train.iloc[0:num_to_use,6:7] \n",
    "    identity_hate_labels = train.iloc[0:num_to_use,7:8] \n",
    "    \n",
    "    return toxic_train_labels, severe_toxic_labels, obscene_labels, threat_labels, insult_labels, identity_hate_labels\n",
    "\n",
    "toxic_train_labels, severe_toxic_labels, obscene_labels, threat_labels, insult_labels, identity_hate_labels = get_labels_as_cols(len(train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 2845813)\n"
     ]
    }
   ],
   "source": [
    "#vectorize inputs\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def vectorize_tfidf(): \n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, stop_words='english')\n",
    "    features_train = vectorizer.fit_transform(train_comments)\n",
    "    features_test = vectorizer.fit_transform(test_comments)\n",
    "    train_vocab = vectorizer.get_feature_names()\n",
    "#     print(train_vocab)\n",
    "    return features_train, features_test, vectorizer\n",
    "\n",
    "def vectorize_count():\n",
    "    vectorizer = CountVectorizer(max_df=0.5, stop_words='english', ngram_range=(1,2))\n",
    "    features_train = vectorizer.fit_transform(train_comments)\n",
    "    features_test = vectorizer.fit_transform(test_comments)\n",
    "    train_vocab = vectorizer.get_feature_names()\n",
    "#     print(train_vocab)\n",
    "    return features_train, features_test, vectorizer\n",
    "\n",
    "\n",
    "count_features_train, count_features_test, count_vectorizer = vectorize_count()\n",
    "\n",
    "tfidf_features_train, tfidf_features_test, tfidf_vectorizer = vectorize_tfidf()\n",
    "\n",
    "print(count_features_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score, accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def train_model(labels):\n",
    "    model = MultinomialNB()\n",
    "    model.fit(features_train, labels)\n",
    "    score = model.score(features_train, labels)\n",
    "    return score, model\n",
    "\n",
    "\n",
    "def get_avg_cvd_score(model, X, y):\n",
    "    to_get = { 'accuracy' : make_scorer(accuracy_score),\n",
    "    'precision' : make_scorer(precision_score, average='macro'),\n",
    "    'recall' : make_scorer(recall_score, average='macro')}\n",
    "    results = cross_validate(model, X, y, scoring=to_get, cv=5)\n",
    "\n",
    "    return np.average(results['test_accuracy']), np.average(results['test_precision']), np.average(results['test_recall'])\n",
    "\n",
    "#toxic\n",
    "score_toxic, _ = train_model(toxic_train_labels.values.ravel())\n",
    "toxic_accuracy, toxic_precision, toxic_recall = get_avg_cvd_score(MultinomialNB(), features_train, toxic_train_labels.values.ravel())\n",
    "print(\"toxic\")\n",
    "print(\"training accuracy: \" + str(score_toxic))\n",
    "print(\"validation accuracy: \" + str(toxic_accuracy))\n",
    "print(\"precision: \" +str(toxic_precision))\n",
    "print(\"recall: \" +str(toxic_recall))\n",
    "print(\"\\n\")\n",
    "\n",
    "#severe_toxic_labels\n",
    "print(\"severe_toxic\")\n",
    "score_severe_toxic, _ = train_model(severe_toxic_labels.values.ravel())\n",
    "toxic_accuracy, toxic_precision, toxic_recall = get_avg_cvd_score(MultinomialNB(), features_train, severe_toxic_labels.values.ravel())\n",
    "print(score_severe_toxic)\n",
    "print(\"validation accuracy: \" + str(toxic_accuracy))\n",
    "print(\"precision: \" +str(toxic_precision))\n",
    "print(\"recall: \" +str(toxic_recall))\n",
    "print(\"\\n\")\n",
    "\n",
    "#obscene_labels\n",
    "print(\"obscene\")\n",
    "score_obscene, _ = train_model(obscene_labels.values.ravel())\n",
    "toxic_accuracy, toxic_precision, toxic_recall = get_avg_cvd_score(MultinomialNB(), features_train, obscene_labels.values.ravel())\n",
    "print(score_obscene)\n",
    "print(\"validation accuracy: \" + str(toxic_accuracy))\n",
    "print(\"precision: \" +str(toxic_precision))\n",
    "print(\"recall: \" +str(toxic_recall))\n",
    "print(\"\\n\")\n",
    "\n",
    "#threat_labels\n",
    "print(\"threat\")\n",
    "score_threat, _ = train_model(threat_labels.values.ravel())\n",
    "toxic_accuracy, toxic_precision, toxic_recall = get_avg_cvd_score(MultinomialNB(), features_train, threat_labels.values.ravel())\n",
    "print(score_threat)\n",
    "print(\"validation accuracy: \" + str(toxic_accuracy))\n",
    "print(\"precision: \" +str(toxic_precision))\n",
    "print(\"recall: \" +str(toxic_recall))\n",
    "print(\"\\n\")\n",
    "\n",
    "#insult_labels\n",
    "print(\"insult\")\n",
    "score_insult, _ = train_model(insult_labels.values.ravel())\n",
    "toxic_accuracy, toxic_precision, toxic_recall = get_avg_cvd_score(MultinomialNB(), features_train, insult_labels.values.ravel())\n",
    "print(score_insult)\n",
    "print(\"validation accuracy: \" + str(toxic_accuracy))\n",
    "print(\"precision: \" +str(toxic_precision))\n",
    "print(\"recall: \" +str(toxic_recall))\n",
    "print(\"\\n\")\n",
    "\n",
    "#identity_hate_labels\n",
    "print(\"identity_hate\")\n",
    "score_identity_hate, _ = train_model(identity_hate_labels.values.ravel())\n",
    "toxic_accuracy, toxic_precision, toxic_recall = get_avg_cvd_score(MultinomialNB(), features_train, identity_hate_labels.values.ravel())\n",
    "print(score_identity_hate)\n",
    "print(\"validation accuracy: \" + str(toxic_accuracy))\n",
    "print(\"precision: \" +str(toxic_precision))\n",
    "print(\"recall: \" +str(toxic_recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "before: 63978\n",
      "before: 63978\n",
      "after: 63978\n",
      "after: 63978\n",
      "labels:                   id  toxic  severe_toxic  obscene  threat  insult  \\\n",
      "5   0001ea8717f6de06      0             0        0       0       0   \n",
      "7   000247e83dcc1211      0             0        0       0       0   \n",
      "11  0002f87b16116a7f      0             0        0       0       0   \n",
      "13  0003e1cccfd5a40a      0             0        0       0       0   \n",
      "14  00059ace3e3e9a53      0             0        0       0       0   \n",
      "16  000663aff0fffc80      0             0        0       0       0   \n",
      "17  000689dd34e20979      0             0        0       0       0   \n",
      "19  000844b52dee5f3f      0             0        0       0       0   \n",
      "21  00091c35fa9d0465      1             0        0       0       0   \n",
      "22  000968ce11f5ee34      0             0        0       0       0   \n",
      "\n",
      "    identity_hate  \n",
      "5               0  \n",
      "7               0  \n",
      "11              0  \n",
      "13              0  \n",
      "14              0  \n",
      "16              0  \n",
      "17              0  \n",
      "19              0  \n",
      "21              0  \n",
      "22              0  \n"
     ]
    }
   ],
   "source": [
    "#clean test data\n",
    "# print(test[0:5])\n",
    "# print(test_labels.loc[test_labels['toxic'] == 1])\n",
    "# print(test_labels[0:15])\n",
    "\n",
    "#remove all unlabeled test data \n",
    "unlabeled = []\n",
    "unlabeled.extend(test_labels.index[test_labels['toxic'] == -1])\n",
    "print(len(test_labels.loc[test_labels['toxic'] == -1]))\n",
    "print(\"before: \" + str(len(test)))\n",
    "print(\"before: \" + str(len(test_labels)))\n",
    "test_labels = test_labels.drop(test_labels.index[unlabeled])\n",
    "test = test.drop(test.index[unlabeled])\n",
    "print(\"after: \" + str(len(test)))\n",
    "print(\"after: \" + str(len(test_labels)))\n",
    "print(\"labels: \" + str(test_labels[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "[0 0 0 ... 0 1 0]\n",
      "severe_toxic\n",
      "obscene\n",
      "threat\n",
      "insult\n",
      "identity_hate\n",
      "<bound method NDFrame.head of        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "0          0             0        0       0       0              0\n",
      "1          0             0        0       0       0              0\n",
      "2          0             0        0       0       0              0\n",
      "3          0             0        0       0       0              0\n",
      "4          0             0        0       0       0              0\n",
      "5          0             0        0       0       0              0\n",
      "6          0             0        0       0       0              0\n",
      "7          0             0        0       0       0              0\n",
      "8          0             0        0       0       0              0\n",
      "9          0             0        0       0       0              0\n",
      "10         0             0        0       0       0              0\n",
      "11         0             0        0       0       0              0\n",
      "12         0             0        0       0       0              0\n",
      "13         0             0        0       0       0              0\n",
      "14         0             0        0       0       0              0\n",
      "15         0             0        0       0       0              0\n",
      "16         0             0        0       0       0              0\n",
      "17         0             0        0       0       0              0\n",
      "18         0             0        0       0       0              0\n",
      "19         0             0        0       0       0              0\n",
      "20         0             0        0       0       0              0\n",
      "21         0             0        0       0       0              0\n",
      "22         0             0        0       0       0              0\n",
      "23         0             0        0       0       0              0\n",
      "24         1             0        1       0       1              0\n",
      "25         0             0        0       0       0              0\n",
      "26         0             0        0       0       0              0\n",
      "27         0             0        0       0       0              0\n",
      "28         0             0        0       0       0              0\n",
      "29         1             0        1       0       1              0\n",
      "...      ...           ...      ...     ...     ...            ...\n",
      "63948      0             0        0       0       0              0\n",
      "63949      0             0        0       0       0              0\n",
      "63950      0             0        0       0       0              0\n",
      "63951      0             0        0       0       0              0\n",
      "63952      0             0        0       0       0              0\n",
      "63953      0             0        0       0       0              0\n",
      "63954      0             0        0       0       0              0\n",
      "63955      0             0        0       0       0              0\n",
      "63956      0             0        0       0       0              0\n",
      "63957      0             0        0       0       0              0\n",
      "63958      0             0        0       0       0              0\n",
      "63959      0             0        0       0       0              0\n",
      "63960      0             0        0       0       0              0\n",
      "63961      0             0        0       0       0              0\n",
      "63962      0             0        0       0       0              0\n",
      "63963      0             0        0       0       0              0\n",
      "63964      0             0        0       0       0              0\n",
      "63965      0             0        0       0       0              0\n",
      "63966      0             0        0       0       0              0\n",
      "63967      0             0        0       0       0              0\n",
      "63968      0             0        0       0       0              0\n",
      "63969      0             0        0       0       0              0\n",
      "63970      0             0        0       0       0              0\n",
      "63971      0             0        0       0       0              0\n",
      "63972      0             0        0       0       0              0\n",
      "63973      0             0        0       0       0              0\n",
      "63974      0             0        0       0       0              0\n",
      "63975      0             0        0       0       0              0\n",
      "63976      1             0        1       0       0              0\n",
      "63977      0             0        0       0       0              0\n",
      "\n",
      "[63978 rows x 6 columns]>\n",
      "63978\n",
      "labels:                   id  toxic  severe_toxic  obscene  threat  insult  \\\n",
      "5   0001ea8717f6de06      0             0        0       0       0   \n",
      "7   000247e83dcc1211      0             0        0       0       0   \n",
      "11  0002f87b16116a7f      0             0        0       0       0   \n",
      "13  0003e1cccfd5a40a      0             0        0       0       0   \n",
      "14  00059ace3e3e9a53      0             0        0       0       0   \n",
      "16  000663aff0fffc80      0             0        0       0       0   \n",
      "17  000689dd34e20979      0             0        0       0       0   \n",
      "19  000844b52dee5f3f      0             0        0       0       0   \n",
      "21  00091c35fa9d0465      1             0        0       0       0   \n",
      "22  000968ce11f5ee34      0             0        0       0       0   \n",
      "\n",
      "    identity_hate  \n",
      "5               0  \n",
      "7               0  \n",
      "11              0  \n",
      "13              0  \n",
      "14              0  \n",
      "16              0  \n",
      "17              0  \n",
      "19              0  \n",
      "21              0  \n",
      "22              0  \n"
     ]
    }
   ],
   "source": [
    "#run test data: we will use tfidf for severe toxic, threat, and identity hate\n",
    "#and we will use countvectorizer: less severe labels, i.e. toxic, obscene, and insult.\n",
    "def get_data(num_to_use, data): \n",
    "    comments = data.iloc[0:num_to_use,1]\n",
    "    return comments\n",
    "\n",
    "test_comments = get_data(len(test), test)\n",
    "# print(test_comments)\n",
    "train_comments = get_data(len(train), train)\n",
    "# print(train_comments)\n",
    "\n",
    "def vectorize_tfidf(): \n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, stop_words='english')\n",
    "    features_train = vectorizer.fit_transform(train_comments)\n",
    "    features_test = vectorizer.transform(test_comments)\n",
    "    train_vocab = vectorizer.get_feature_names()\n",
    "#     print(train_vocab)\n",
    "    return features_train, features_test, vectorizer\n",
    "\n",
    "def vectorize_count():\n",
    "    vectorizer = CountVectorizer(max_df=0.5, stop_words='english', ngram_range=(1,2))\n",
    "    features_train = vectorizer.fit_transform(train_comments)\n",
    "    features_test = vectorizer.transform(test_comments)\n",
    "    train_vocab = vectorizer.get_feature_names()\n",
    "#     print(train_vocab)\n",
    "    return features_train, features_test, vectorizer\n",
    "\n",
    "def get_test_labels_as_cols(num_to_use, test_labels):\n",
    "    #labels as pd dataframes\n",
    "    toxic_train_labels = test_labels.iloc[0:num_to_use,2:3]\n",
    "    severe_toxic_labels = test_labels.iloc[0:num_to_use,3:4] \n",
    "    obscene_labels = test_labels.iloc[0:num_to_use,4:5] \n",
    "    threat_labels = test_labels.iloc[0:num_to_use,5:6] \n",
    "    insult_labels = test_labels.iloc[0:num_to_use,6:7] \n",
    "    identity_hate_labels = test_labels.iloc[0:num_to_use,7:8] \n",
    "    \n",
    "    return toxic_train_labels, severe_toxic_labels, obscene_labels, threat_labels, insult_labels, identity_hate_labels\n",
    "\n",
    "def train_model(labels, features):\n",
    "    model = MultinomialNB()\n",
    "    model.fit(features, labels)\n",
    "    score = model.score(features, labels)\n",
    "    return score, model\n",
    "\n",
    "count_features_train, count_features_test, count_vectorizer = vectorize_count()\n",
    "tfidf_features_train, tfidf_features_test, tfidf_vectorizer = vectorize_tfidf()\n",
    "\n",
    "toxic_train_labels, severe_toxic_labels, obscene_labels, threat_labels, insult_labels, identity_hate_labels = get_test_labels_as_cols(len(train), train)\n",
    "\n",
    "#toxic\n",
    "#train model, then get labels for test data\n",
    "print(\"toxic\")\n",
    "score_toxic, model = train_model(toxic_train_labels.values.ravel(), count_features_train)\n",
    "toxic_labels = model.predict(count_features_test)\n",
    "\n",
    "# severe_toxic_labels\n",
    "print(\"severe_toxic\")\n",
    "score_severe_toxic, model = train_model(severe_toxic_labels.values.ravel(), tfidf_features_train)\n",
    "severe_toxic_labels = model.predict(tfidf_features_test)\n",
    "\n",
    "\n",
    "# #obscene_labels\n",
    "print(\"obscene\")\n",
    "score_obscene, model = train_model(obscene_labels.values.ravel(), count_features_train)\n",
    "obscene_labels = model.predict(count_features_test)\n",
    "\n",
    "#threat_labels\n",
    "print(\"threat\")\n",
    "score_threat, model = train_model(threat_labels.values.ravel(), tfidf_features_train)\n",
    "threat_labels = model.predict(tfidf_features_test)\n",
    "\n",
    "#insult_labels\n",
    "print(\"insult\")\n",
    "score_insult, model = train_model(insult_labels.values.ravel(), count_features_train)\n",
    "insult_labels = model.predict(count_features_test)\n",
    "\n",
    "# identity_hate_labels\n",
    "print(\"identity_hate\")\n",
    "score_identity_hate, model = train_model(identity_hate_labels.values.ravel(), tfidf_features_train)\n",
    "identity_hate_labels = model.predict(tfidf_features_test)\n",
    "\n",
    "\n",
    "#combine all labels\n",
    "labels = pd.DataFrame({'toxic': toxic_labels, 'severe_toxic': severe_toxic_labels, 'obscene': obscene_labels, 'threat': threat_labels, 'insult': insult_labels, 'identity_hate': identity_hate_labels})\n",
    "print(labels.head)\n",
    "print(len(labels))\n",
    "print(\"labels: \" + str(test_labels[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num predicted labels: 63978\n",
      "num actual labels: 63978\n",
      "toxic_accuracy: 0.9322892244208947\n",
      "severe_toxic_accuracy: 0.9942636531307637\n",
      "obscene_accuracy: 0.9572352996342492\n",
      "threat_accuracy: 0.9967019913095126\n",
      "insult_accuracy: 0.954453093250805\n",
      "identity_hate_accuracy: 0.9888711744662227\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy\n",
    "print(\"num predicted labels: \" + str(len(labels)))\n",
    "print(\"num actual labels: \" + str(len(test_labels)))\n",
    "\n",
    "#drop indices so we can compare \n",
    "labels = labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "total = len(res)\n",
    "\n",
    "#toxic\n",
    "res = np.where(labels['toxic'] == test_labels['toxic'], 1, 0)\n",
    "count_correct = sum(res)\n",
    "toxic_accuracy = count_correct/total\n",
    "print(\"toxic_accuracy: \" + str(toxic_accuracy))\n",
    "\n",
    "#severe_toxic\n",
    "res = np.where(labels['severe_toxic'] == test_labels['severe_toxic'], 1, 0)\n",
    "count_correct = sum(res)\n",
    "accuracy = count_correct/total\n",
    "print(\"severe_toxic_accuracy: \" + str(accuracy))\n",
    "\n",
    "#obscene\n",
    "res = np.where(labels['obscene'] == test_labels['obscene'], 1, 0)\n",
    "count_correct = sum(res)\n",
    "accuracy = count_correct/total\n",
    "print(\"obscene_accuracy: \" + str(accuracy))\n",
    "\n",
    "#threat\n",
    "res = np.where(labels['threat'] == test_labels['threat'], 1, 0)\n",
    "count_correct = sum(res)\n",
    "accuracy = count_correct/total\n",
    "print(\"threat_accuracy: \" + str(accuracy))\n",
    "\n",
    "#insult\n",
    "res = np.where(labels['insult'] == test_labels['insult'], 1, 0)\n",
    "count_correct = sum(res)\n",
    "accuracy = count_correct/total\n",
    "print(\"insult_accuracy: \" + str(accuracy))\n",
    "\n",
    "#identity hate\n",
    "res = np.where(labels['identity_hate'] == test_labels['identity_hate'], 1, 0)\n",
    "count_correct = sum(res)\n",
    "accuracy = count_correct/total\n",
    "print(\"identity_hate_accuracy: \" + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "0.9753150635140471\n",
      "severe_toxic\n",
      "0.9899417814013824\n",
      "obscene\n",
      "0.9827976261350747\n",
      "threat\n",
      "0.9969856678218473\n",
      "insult\n",
      "0.9793195505448985\n",
      "identity_hate\n",
      "0.9911387407486323\n"
     ]
    }
   ],
   "source": [
    "#train model on all data (including the labeled test data + given train data)\n",
    "#run test data: we will use tfidf for severe toxic, threat, and identity hate\n",
    "#and we will use countvectorizer: less severe labels, i.e. toxic, obscene, and insult.\n",
    "def get_data(num_to_use, data): \n",
    "    comments = data.iloc[0:num_to_use,1]\n",
    "    return comments\n",
    "\n",
    "test_comments = get_data(len(test), test)\n",
    "# print(test_comments)\n",
    "train_comments = get_data(len(train), train)\n",
    "# print(train_comments)\n",
    "\n",
    "#combine the comments \n",
    "comments = pd.concat([train_comments, test_comments])\n",
    "# print(comments)\n",
    "\n",
    "# #combine the labels: drop indices \n",
    "# print(len(train) + len(test_labels))\n",
    "train_labels = train.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "labels = pd.concat([train_labels, test_labels], sort=False)\n",
    "# print(len(labels))\n",
    "\n",
    "def vectorize_tfidf(): \n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, stop_words='english')\n",
    "    features_train = vectorizer.fit_transform(train_comments)\n",
    "    features_test = vectorizer.transform(test_comments)\n",
    "    train_vocab = vectorizer.get_feature_names()\n",
    "#     print(train_vocab)\n",
    "    return features_train, features_test, vectorizer\n",
    "\n",
    "def vectorize_count():\n",
    "    vectorizer = CountVectorizer(max_df=0.5, stop_words='english', ngram_range=(1,2))\n",
    "    features_train = vectorizer.fit_transform(train_comments)\n",
    "    features_test = vectorizer.transform(test_comments)\n",
    "    train_vocab = vectorizer.get_feature_names()\n",
    "#     print(train_vocab)\n",
    "    return features_train, features_test, vectorizer\n",
    "\n",
    "def get_test_labels_as_cols(num_to_use, test_labels):\n",
    "    #labels as pd dataframes\n",
    "    toxic_train_labels = test_labels.iloc[0:num_to_use,2:3]\n",
    "    severe_toxic_labels = test_labels.iloc[0:num_to_use,3:4] \n",
    "    obscene_labels = test_labels.iloc[0:num_to_use,4:5] \n",
    "    threat_labels = test_labels.iloc[0:num_to_use,5:6] \n",
    "    insult_labels = test_labels.iloc[0:num_to_use,6:7] \n",
    "    identity_hate_labels = test_labels.iloc[0:num_to_use,7:8] \n",
    "    \n",
    "    return toxic_train_labels, severe_toxic_labels, obscene_labels, threat_labels, insult_labels, identity_hate_labels\n",
    "\n",
    "def train_model(labels, features):\n",
    "    model = MultinomialNB()\n",
    "    model.fit(features, labels)\n",
    "    score = model.score(features, labels)\n",
    "    return score, model\n",
    "\n",
    "count_features_train, count_features_test, count_vectorizer = vectorize_count()\n",
    "tfidf_features_train, tfidf_features_test, tfidf_vectorizer = vectorize_tfidf()\n",
    "\n",
    "toxic_train_labels, severe_toxic_labels, obscene_labels, threat_labels, insult_labels, identity_hate_labels = get_test_labels_as_cols(len(train), train)\n",
    "\n",
    "#toxic\n",
    "#train model, then get labels for test data\n",
    "print(\"toxic\")\n",
    "score, model_toxic = train_model(toxic_train_labels.values.ravel(), count_features_train)\n",
    "toxic_labels = model_toxic.predict(count_features_test)\n",
    "print(score)\n",
    "\n",
    "# severe_toxic_labels\n",
    "print(\"severe_toxic\")\n",
    "score, model_severe = train_model(severe_toxic_labels.values.ravel(), tfidf_features_train)\n",
    "severe_toxic_labels = model_severe.predict(tfidf_features_test)\n",
    "print(score)\n",
    "\n",
    "\n",
    "# #obscene_labels\n",
    "print(\"obscene\")\n",
    "score, model_obscene = train_model(obscene_labels.values.ravel(), count_features_train)\n",
    "obscene_labels = model_obscene.predict(count_features_test)\n",
    "print(score)\n",
    "\n",
    "#threat_labels\n",
    "print(\"threat\")\n",
    "score, model_threat = train_model(threat_labels.values.ravel(), tfidf_features_train)\n",
    "threat_labels = model_threat.predict(tfidf_features_test)\n",
    "print(score)\n",
    "\n",
    "#insult_labels\n",
    "print(\"insult\")\n",
    "score, model_insult = train_model(insult_labels.values.ravel(), count_features_train)\n",
    "insult_labels = model_insult.predict(count_features_test)\n",
    "print(score)\n",
    "\n",
    "# identity_hate_labels\n",
    "print(\"identity_hate\")\n",
    "score, model_identity_hate = train_model(identity_hate_labels.values.ravel(), tfidf_features_train)\n",
    "identity_hate_labels = model_identity_hate.predict(tfidf_features_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "severe_toxic\n",
      "obscene\n",
      "threat\n",
      "insult\n",
      "identity_hate\n"
     ]
    }
   ],
   "source": [
    "#load tweets and find the toxic tweets\n",
    "tweet_path = \"./data/tweetsUsers.csv\"\n",
    "\n",
    "#load data with pandas and return dataframes \n",
    "def load_tweets(tweet_path):\n",
    "    tweets = pd.read_csv(tweet_path)\n",
    "    comments = tweets['text']\n",
    "    users = tweets['screen_name']\n",
    "    return comments, users\n",
    "\n",
    "tweets, users = load_tweets(tweet_path)\n",
    "\n",
    "#print(tweets[0:10])\n",
    "\n",
    "def vectorize_tfidf(docs): \n",
    "    features = tfidf_vectorizer.transform(docs)\n",
    "    return features\n",
    "\n",
    "def vectorize_count(docs):\n",
    "    features = count_vectorizer.transform(docs)\n",
    "    return features\n",
    "\n",
    "count_features_test = vectorize_count(tweets)\n",
    "tfidf_features_test = vectorize_tfidf(tweets)\n",
    "\n",
    "#toxic\n",
    "#train model, then get labels for test data\n",
    "print(\"toxic\")\n",
    "toxic_labels = model_toxic.predict(count_features_test)\n",
    "\n",
    "# severe_toxic_labels\n",
    "print(\"severe_toxic\")\n",
    "severe_toxic_labels = model_severe.predict(tfidf_features_test)\n",
    "\n",
    "# #obscene_labels\n",
    "print(\"obscene\")\n",
    "obscene_labels = model_obscene.predict(count_features_test)\n",
    "\n",
    "#threat_labels\n",
    "print(\"threat\")\n",
    "threat_labels = model_threat.predict(tfidf_features_test)\n",
    "\n",
    "#insult_labels\n",
    "print(\"insult\")\n",
    "insult_labels = model_insult.predict(count_features_test)\n",
    "\n",
    "# identity_hate_labels\n",
    "print(\"identity_hate\")\n",
    "identity_hate_labels = model_identity_hate.predict(tfidf_features_test)\n",
    "    \n",
    "#combine labels\n",
    "labels = pd.DataFrame({'toxic': toxic_labels, 'severe_toxic': severe_toxic_labels, 'obscene': obscene_labels, 'threat': threat_labels, 'insult': insult_labels, 'identity_hate': identity_hate_labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data analysis\n",
    "num_toxic = sum(np.where(labels['toxic'] == 1, 1, 0))\n",
    "toxic = labels.index[labels['toxic'] == 1].tolist()\n",
    "severe = labels.index[labels['severe_toxic'] == 1].tolist()\n",
    "obscene = labels.index[labels['obscene'] == 1].tolist()\n",
    "threat = labels.index[labels['threat'] == 1].tolist()\n",
    "insult = labels.index[labels['insult'] == 1].tolist()\n",
    "identity_hate = labels.index[labels['identity_hate'] == 1].tolist()\n",
    "\n",
    "# print(tweets.loc[toxic])\n",
    "# print(users.loc[toxic])\n",
    "flagged_users = pd.concat([users.loc[toxic], users.loc[severe], users.loc[obscene], users.loc[threat], users.loc[insult], users.loc[identity_hate]])\n",
    "flagged_tweets = pd.concat([tweets.loc[toxic], tweets.loc[severe], tweets.loc[obscene], tweets.loc[threat], tweets.loc[insult], tweets.loc[identity_hate]])\n",
    "\n",
    "df = pd.DataFrame({'users': flagged_users, 'tweets': flagged_tweets})\n",
    "\n",
    "df.drop_duplicates() #remove any repeated comments\n",
    "df.sort_values(by=['users'])\n",
    "df.to_csv(\"data/toxic_tweets1.csv\")\n",
    "\n",
    "\n",
    "# num_toxic = sum(np.where(labels['severe_toxic'] == 1, 1, 0))\n",
    "# print(num_toxic)\n",
    "\n",
    "# num_toxic = sum(np.where(labels['obscene'] == 1, 1, 0))\n",
    "# print(num_toxic)\n",
    "\n",
    "# num_toxic = sum(np.where(labels['threat'] == 1, 1, 0))\n",
    "# print(num_toxic)\n",
    "\n",
    "# num_toxic = sum(np.where(labels['insult'] == 1, 1, 0))\n",
    "# print(num_toxic)\n",
    "\n",
    "# num_toxic = sum(np.where(labels['identity_hate'] == 1, 1, 0))\n",
    "# print(num_toxic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " def summarize():\n",
    "    count_tweets = pd.DataFrame({'users':users, 'tweets': tweets})\n",
    "    user_total = count_tweets.groupby(['users']).count()\n",
    "    user_flagged = df.groupby(['users']).count()\n",
    "    percent = user_flagged/user_total * 100\n",
    "    percent.plot(kind='bar', title=\"Toxic Tweets by User (as percent of total tweets by user)\")\n",
    "\n",
    "summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# from langdetect import detect\n",
    "# import re\n",
    "\n",
    "# sentence = \"\"\n",
    "# vocab = list(vectorizer.vocabulary_.keys())\n",
    "# cut = int(3.0 * len(vocab) / 4.0)\n",
    "# vocab = vocab[:len(vocab) - cut]\n",
    "# sentenceLength = int(random.random() * 8) + 3\n",
    "# for i in range(sentenceLength):\n",
    "#     word = \"\"\n",
    "#     isEnglish = False\n",
    "#     while not isEnglish:\n",
    "#         falloff = 5\n",
    "#         sample = random.random() ** falloff\n",
    "#         index = int(sample * len(vocab))\n",
    "#         word = vocab[index]\n",
    "#         word = \"\".join(re.split(\"[^a-zA-Z]*\", word))\n",
    "#         if word == \"\":\n",
    "#             continue\n",
    "#         isEnglish = (detect(word) == \"en\")\n",
    "    \n",
    "#     sentence += \" \" + word\n",
    "    \n",
    "# print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
